# Configuration for Training Dataset Generator
# 训练数据集生成器配置

# Pipeline settings / 流水线设置
pipeline:
  # Directories for each stage
  # 各阶段的目录
  slices_dir: "slices"
  reviewed_slices_dir: "reviewed_slices"
  batch_input_dir: "batch_input"
  batch_output_dir: "batch_output"
  final_output_dir: "final_output"
  
  # Repositories to process
  # 要处理的仓库
  repositories:
    - name: "nsidnev/fastapi-realworld-example-app"
      url: "https://github.com/nsidnev/fastapi-realworld-example-app.git"
      max_files: 50
    # Add more repositories as needed
    # 根据需要添加更多仓库
    # - name: "pallets/flask"
    #   url: "https://github.com/pallets/flask.git"
    #   max_files: 30
    # - name: "psf/requests"
    #   url: "https://github.com/psf/requests.git"
    #   max_files: 30
  
  # Scenario splitting strategy
  # 场景分割策略
  scenario_split:
    # Use functions for Scenario 1 (Q&A)
    # 场景1使用函数（问答）
    scenario1_types: ["function"]
    # Use classes for Scenario 2 (Design)
    # 场景2使用类（设计）
    scenario2_types: ["class"]
  
  # Batch size limits
  # 批处理大小限制
  max_scenario1_items: 100
  max_scenario2_items: 50
  
  # Shuffle settings
  # 随机打乱设置
  shuffle_dataset: true
  random_seed: 42

# Analysis settings / 分析设置
analysis:
  # Supported programming languages
  languages:
    - python
  
  # Maximum directory depth for code analysis
  max_depth: 3
  
  # Include test files in analysis
  include_tests: false
  
  # Maximum number of files to analyze (null for all)
  max_files: null
  
  # Exclude patterns
  exclude_patterns:
    - "*/tests/*"
    - "*/test/*"
    - "*/__pycache__/*"
    - "*/venv/*"
    - "*/env/*"
    - "*/.git/*"

# Generation settings / 生成设置
generation:
  # Number of Q&A pairs to generate per file
  qa_pairs_per_file: 5
  
  # Minimum complexity to include
  min_complexity: "simple"
  
  # Include reasoning traces
  include_reasoning: true
  
  # Maximum Q&A pairs total
  max_qa_pairs: 100
  
  # Maximum design solutions
  max_design_solutions: 10
  
  # Languages to generate
  languages:
    - en
    - zh

# Quality settings / 质量设置
quality:
  # Minimum code snippet length (lines)
  min_code_lines: 5
  
  # Maximum code snippet length (lines)
  max_code_lines: 50
  
  # Minimum diversity threshold (0.0 to 1.0)
  diversity_threshold: 0.7
  
  # Validation rules
  validation:
    check_completeness: true
    check_consistency: true
    check_relevance: true

# Output settings / 输出设置
output:
  # Output format (json, jsonl)
  format: "jsonl"
  
  # Generate bilingual datasets
  bilingual: true
  
  # Split into train/test sets
  split_train_test: true
  
  # Test set ratio
  test_ratio: 0.2
  
  # Output directory (for legacy direct generation)
  output_dir: "./output"
  
  # Split by language into separate files
  split_by_language: true
  
  # Pretty print JSON (indentation)
  json_indent: 2

# Repository settings / 仓库设置
repository:
  # Clone directory for repositories
  clone_dir: "/tmp/datasets"
  
  # Cleanup cloned repos after generation
  cleanup_after: false
  
  # Default branch
  default_branch: "main"

# Logging settings / 日志设置
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: null  # Set to file path to enable file logging
